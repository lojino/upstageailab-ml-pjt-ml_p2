
'''ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì •'''
import os
import pandas as pd
import joblib
from datetime import datetime

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.datasets import load_iris

import mlflow
import mlflow.sklearn  # sklearn ëª¨ë¸ì„ ë¡œê¹…í•  ë•Œ ì‚¬ìš©

import airflow 
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.slack.operators.slack_webhook import SlackWebhookOperator

## ì™¸ë¶€ ìš”ì²­ ì´ìŠˆ í•´ê²°
os.environ['NO_PROXY'] = '*'  # macì—ì„œ airflowë¡œ ì™¸ë¶€ ìš”ì²­í•  ë•Œ ì´ìŠˆê°€ ìžˆìŒ. í•˜ì—¬ í•´ë‹¹ ì½”ë“œ ì¶”ê°€ í•„ìš”

## MLflow í™˜ê²½ ì„¤ì • (ì‹¤ì œ í™˜ê²½ì— ë§žê²Œ ìˆ˜ì •)
mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI'))
# mlflow.set_tracking_uri("http://127.0.0.1:5000")  # MLflow ì„œë²„ URI => mlflow ui
mlflow.set_experiment("Iris_Model_Training")  # ì‹¤í—˜ ì´ë¦„ ì„¤ì •

default_args = {
    'owner': 'admin',
    'start_date': datetime(2024, 11, 22),
    'retries': 1,
}


## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬ ì§„í–‰ 
def prepare_data(**context):
    iris = load_iris()
    X = pd.DataFrame(iris.data, columns=iris.feature_names)
    y = pd.Series(iris.target)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # XComì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ í•¨ìˆ˜ ê°„ ì „ë‹¬
    context['ti'].xcom_push(key='X_train', value=X_train.to_json())
    context['ti'].xcom_push(key='X_test', value=X_test.to_json())
    context['ti'].xcom_push(key='y_train', value=y_train.to_json(orient='records'))
    context['ti'].xcom_push(key='y_test', value=y_test.to_json(orient='records'))

## ëª¨ë¸ í•™ìŠµ ë° mlflow ë¡œê¹…
def train_model(model_name, **context):
    ti = context['ti']
    X_train = pd.read_json(ti.xcom_pull(key='X_train'))
    y_train = pd.read_json(ti.xcom_pull(key='y_train'), typ='series')

    mlflow.autolog()
    
    # í•™ìŠµ ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ
    with mlflow.start_run(run_name=model_name):
        if model_name == 'RandomForest':
            model = RandomForestClassifier(n_estimators=100, random_state=42)
        elif model_name == 'GradientBoosting':
            model = GradientBoostingClassifier(random_state=42)
        elif model_name == 'SVM':
            model = SVC()
        else:
            raise ValueError(f"Unsupported model: {model_name}")

        # ëª¨ë¸ í•™ìŠµ
        model.fit(X_train, y_train)

        # ëª¨ë¸ ë¡œê¹…
        mlflow.sklearn.log_model(model, model_name)
        mlflow.log_param("model_name", model_name)
        
        # ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ìž¥
        model_path = f'/tmp/{model_name}_model.pkl' # S3ì—ë„ ì—…ë¡œë“œ
        joblib.dump(model, model_path)

        context['ti'].xcom_push(key=f'model_path_{model_name}', value=model_path)

## ëª¨ë¸ í‰ê°€ ë° mlflow ë¡œê¹…
def evaluate_model(model_name, **context):
    ti = context['ti']
    model_path = ti.xcom_pull(key=f'model_path_{model_name}')
    model = joblib.load(model_path)

    X_test = pd.read_json(ti.xcom_pull(key='X_test'))
    y_test = pd.read_json(ti.xcom_pull(key='y_test'), typ='series')

    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)

    # MLflowì— ë©”íŠ¸ë¦­ ë¡œê¹…
    with mlflow.start_run(run_name=model_name):
        mlflow.log_metric("accuracy", accuracy)
    
    print(f"{model_name} Model Accuracy: {accuracy}")

    context['ti'].xcom_push(key=f'performance_{model_name}', value=accuracy)

## ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
def select_best_model(**context):
    ti = context['ti']

    rf_performance = ti.xcom_pull(key='performance_RandomForest')
    gb_performance = ti.xcom_pull(key='performance_GradientBoosting')
    svm_performance = ti.xcom_pull(key='performance_SVM')

    performances = {
        'RandomForest': rf_performance,
        'GradientBoosting': gb_performance,
        'SVM': svm_performance
    }

    best_model = max(performances, key=performances.get)
    best_performance = performances[best_model]

    print(f"Best Model: {best_model} with accuracy {best_performance}")
    context['ti'].xcom_push(key='best_model', value=best_model)

## Slack ë©”ì‹œì§€ ì „ì†¡
def send_slack_notification(**context):
    ti = context['ti']
    best_model = ti.xcom_pull(key='best_model')
    rf_performance = ti.xcom_pull(key='performance_RandomForest')
    gb_performance = ti.xcom_pull(key='performance_GradientBoosting')
    svm_performance = ti.xcom_pull(key='performance_SVM')
    
    message = (
        f"ðŸ† **Best Model:** *{best_model}*\n\n"
        f"ðŸ“Š **Model Performances:**\n"
        f"- ðŸŒ² **Random Forest Accuracy:** {rf_performance}\n"
        f"- ðŸš€ **Gradient Boosting Accuracy:** {gb_performance}\n"
        f"- ðŸ–¥ï¸ **SVM Accuracy:** {svm_performance}"
    )
    
    slack_notification = SlackWebhookOperator(
        task_id='send_slack_notification_task',
        slack_webhook_conn_id='slack_webhook',
        message=message,
        dag=context['dag']
    )
    
    # Slack ë©”ì‹œì§€ë¥¼ ì‹¤ì œë¡œ ì „ì†¡
    slack_notification.execute(context=context)

## DAG ì •ì˜
dag = DAG(
    'iris_ml_training_pipeline_with_mlflow',
    default_args=default_args,
    description='A machine learning pipeline with MLflow logging on Iris dataset',
    schedule_interval='@daily',
    catchup=False
)

## Task ì •ì˜
prepare_data_task = PythonOperator(
    task_id='prepare_data',
    python_callable=prepare_data,
    provide_context=True,
    dag=dag,
)

train_rf_task = PythonOperator(
    task_id='train_random_forest',
    python_callable=train_model,
    op_kwargs={'model_name': 'RandomForest'},
    provide_context=True,
    dag=dag,
)

train_gb_task = PythonOperator(
    task_id='train_gradient_boosting',
    python_callable=train_model,
    op_kwargs={'model_name': 'GradientBoosting'},
    provide_context=True,
    dag=dag,
)

train_svm_task = PythonOperator(
    task_id='train_svm',
    python_callable=train_model,
    op_kwargs={'model_name': 'SVM'},
    provide_context=True,
    dag=dag,
)

evaluate_rf_task = PythonOperator(
    task_id='evaluate_random_forest',
    python_callable=evaluate_model,
    op_kwargs={'model_name': 'RandomForest'},
    provide_context=True,
    dag=dag,
)

evaluate_gb_task = PythonOperator(
    task_id='evaluate_gradient_boosting',
    python_callable=evaluate_model,
    op_kwargs={'model_name': 'GradientBoosting'},
    provide_context=True,
    dag=dag,
)

evaluate_svm_task = PythonOperator(
    task_id='evaluate_svm',
    python_callable=evaluate_model,
    op_kwargs={'model_name': 'SVM'},
    provide_context=True,
    dag=dag,
)

select_best_model_task = PythonOperator(
    task_id='select_best_model',
    python_callable=select_best_model,
    provide_context=True,
    dag=dag,
)

# Slack ë©”ì‹œì§€ ì „ì†¡ Task
slack_notification_task = PythonOperator(
    task_id='send_slack_notification',
    python_callable=send_slack_notification,
    provide_context=True,
    dag=dag
)

## Task ì˜ì¡´ì„± ì„¤ì •
prepare_data_task >> [train_rf_task, train_gb_task, train_svm_task]
train_rf_task >> evaluate_rf_task
train_gb_task >> evaluate_gb_task
train_svm_task >> evaluate_svm_task
[evaluate_rf_task, evaluate_gb_task, evaluate_svm_task] >> select_best_model_task >> slack_notification_task







