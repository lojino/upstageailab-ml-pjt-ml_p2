
# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì •
import os
import pandas as pd
import joblib
from datetime import datetime
from datasets import load_dataset, Dataset

import sklearn.model_selection
from sklearn.metrics import accuracy_score


from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import Trainer, TrainingArguments
import torch

import mlflow
import mlflow.sklearn  # sklearn ëª¨ë¸ì„ ë¡œê¹…í•  ë•Œ ì‚¬ìš©

import airflow 
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.slack.operators.slack_webhook import SlackWebhookOperator

## ì™¸ë¶€ ìš”ì²­ ì´ìŠˆ í•´ê²°
os.environ['NO_PROXY'] = '*'  # macì—ì„œ airflowë¡œ ì™¸ë¶€ ìš”ì²­í•  ë•Œ ì´ìŠˆê°€ ìžˆìŒ. í•˜ì—¬ í•´ë‹¹ ì½”ë“œ ì¶”ê°€ í•„ìš”

## MLflow í™˜ê²½ ì„¤ì • (ì‹¤ì œ í™˜ê²½ì— ë§žê²Œ ìˆ˜ì •)
mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI', "http://127.0.0.1:5000"))
# mlflow.set_tracking_uri("http://127.0.0.1:5000")  # MLflow ì„œë²„ URI => mlflow ui
mlflow.set_experiment("IMDB_Model_Training")  # ì‹¤í—˜ ì´ë¦„ ì„¤ì •

default_args = {
    'owner': 'admin',
    'start_date': datetime(2024, 11, 25),
    'retries': 1,
}


## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬ ì§„í–‰ 
def prepare_data(**context):
    data_path = 'IMDB_PJT/airflow/dags/IMDB_Dataset.csv'
    imdb_db = pd.read_csv(data_path, index_col=0)

    dataset = Dataset.dataset.from_pandas(imdb_db)
    dataset = sklearn.model_selection.train_test_split(test_size=0.2)
    
    label2id = {'positive': 1, 'negative': 0}  # ë¼ë²¨ ê°’ ì„¤ì •
    dataset = dataset.map(lambda x: {'label': label2id[x['sentiment']]}) # ë¼ë²¨ ê°’ ë§¤í•‘


    # XComì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ í•¨ìˆ˜ ê°„ ì „ë‹¬
    context['ti'].xcom_push(key='train_dataset', value=dataset['train'].to_json())
    context['ti'].xcom_push(key='test_dataset', value=dataset['test'].to_json())
    context['ti'].xcom_push(key='label2id', value=label2id)

## ëª¨ë¸ í•™ìŠµ ë° mlflow ë¡œê¹…
def train_model(model_name, **context):
    ti = context['ti']
    train_dataset = pd.read_json(ti.xcom_pull(key='train_dataset'))
    test_dataset = pd.read_json(ti.xcom_pull(key='test_dataset'))
    label2id = ti.xcom_pull(key='label2id')

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model_name = 'huawei-noah/TinyBERT_General_4L_312D'
    tokenizer = AutoTokenizer.from_pretrained(model, use_fast=True)

    def tokenize_batch(batch):
        return tokenizer(batch['review'], padding='max_length', truncation=True, max_length=300)
    
    train_dataset = train_dataset.map(tokenize_batch, batched=True, batch_size=None)
    test_dataset = test_dataset.map(tokenize_batch, batched=True, batch_size=None)

    train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])
    test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])

    id2label = {0: 'negative', 1: 'positive'}
    model = AutoModelForSequenceClassification.from_pretrained(
        model_name, 
        num_labels=2, 
        id2label=id2label, 
        label2id=label2id
    ).to(device)


    mlflow.autolog()
    
    # í•™ìŠµ ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ
    with mlflow.start_run(run_name=model_name):
        model_path = f'/tmp/{model_name}_model.pkl'
        trainer = Trainer(
            model=model,
            args=TrainingArguments(output_dir=model_path, num_train_epochs=3),
            train_dataset=train_dataset,
            eval_dataset=test_dataset
        )
        torch.save(model.state_dict(), model_path)
        # ëª¨ë¸ í•™ìŠµ
        trainer.train()

        mlflow.log_artifact(model_path, artifact_path="model")

        context['ti'].xcom_push(key=f'model_path_{model_name}', value=model_path)

## ëª¨ë¸ í‰ê°€ ë° mlflow ë¡œê¹…
def evaluate_model(model_name, **context):
    ti = context['ti']
    model_path = ti.xcom_pull(key=f'model_path_{model_name}')
    test_dataset = pd.read_json(ti.xcom_pull(key='test_dataset'))
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model_name = 'huawei-noah/TinyBERT_General_4L_312D'
    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)
    model.to(device)

    predictions = model.predict(test_dataset)
    accuracy = accuracy_score(test_dataset['label'], predictions)

    # MLflowì— ë©”íŠ¸ë¦­ ë¡œê¹…
    with mlflow.start_run(run_name=model_name):
        mlflow.log_params({"model_name": model_name})
        mlflow.log_metric("accuracy", accuracy)

    context['ti'].xcom_push(key=f'performance_{model_name}', value=accuracy)

## Slack ë©”ì‹œì§€ ì „ì†¡
def send_slack_notification(**context):
    ti = context['ti']
    # best_model = ti.xcom_pull(key='best_model')

    performance = ti.xcom_pull(key='performance_TinyBERT_General_4L_312D')
    message = (
        f"ðŸ“Š **Model Performances:**\n"
        f"- ðŸŒ² **Accuracy:** {performance}\n"
    )
    
    slack_notification = SlackWebhookOperator(
        task_id='send_slack_notification_task',
        slack_webhook_conn_id='slack_webhook',
        message=message,
        dag=context['dag']
    )
    # Slack ë©”ì‹œì§€ë¥¼ ì‹¤ì œë¡œ ì „ì†¡
    slack_notification.execute(context=context)

## DAG ì •ì˜
dag = DAG(
    'IMDB_Model_Training',
    default_args=default_args,
    description='A TinyBERT model training pipeline with MLflow on IMDB dataset',
    schedule_interval='@daily',
    catchup=False
)

## Task ì •ì˜
prepare_data_task = PythonOperator(
    task_id='prepare_data',
    python_callable=prepare_data,
    provide_context=True,
    dag=dag,
)

train_model_task = PythonOperator(
    task_id='train_model',
    python_callable=train_model,
    op_kwargs={'model_name': 'TinyBERT'},
    dag=dag,
)

evaluate_model_task = PythonOperator(
    task_id='evaluate_model',
    python_callable=evaluate_model,
    op_kwargs={'model_name': 'TinyBERT'},
    provide_context=True,
    dag=dag,
)


# Slack ë©”ì‹œì§€ ì „ì†¡ Task
slack_notification_task = PythonOperator(
    task_id='send_slack_notification',
    python_callable=send_slack_notification,
    provide_context=True,
    dag=dag
)

## Task ì˜ì¡´ì„± ì„¤ì •
prepare_data_task >> train_model_task >> evaluate_model_task >> slack_notification_task







